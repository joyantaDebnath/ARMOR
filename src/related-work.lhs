\section{Related Work}





% % Due to the wide adoption of \xfon PKI, the research community has critically analyzed the implementation and deployment of \xfon PKI in recent years. In the following, we provide a brief overview of previous research efforts and explain how our work diverges from them.

% The widespread adoption of X.509 PKI has led to significant scrutiny by the research community regarding its implementation and deployment in recent years. In this section, we provide a concise overview of prior research efforts in this field and clarify how our work diverges from these existing studies.

% % Testing approaches based on \fuzzing~\cite{frank, mucert, nezha, quan2020sadt, chen2023sbdt} and \symex ~\cite{rfcguided, symcert} had been shown as powerful tools for uncovering \textit{logical flaws} in the certificate validation code of many open-source TLS libraries. While these techniques have successfully identified numerous noncompliance issues, they naturally bear the risk of false negatives-- some logical flaws remain undetected, especially when those are common across all tested libraries. To counter this challenge, the presence of a reference implementation that could serve as an oracle and provide a true standard, against which the test results can be verified, became crucial.

% Differential testing based on fuzzing and symbolic execution have proven effective in revealing logical flaws in the certificate validation code of various open-source TLS libraries. These techniques have successfully identified numerous noncompliance issues. However, they inherently risk false negatives, as some logical flaws may go undetected, particularly those that are common across all tested libraries. To address this challenge, developing a formally verified reference implementation serving as an oracle becomes essential. Such an implementation would offer a true standard for verifying test results, ensuring a more comprehensive detection of logical flaws.

% Everparse

% DICE*

% ASN1*

% hummurabi

% % \textbf{Identifying Implementation Flaws:} Testing approaches based on \fuzzing~\cite{frank, mucert, nezha, quan2020sadt, chen2023sbdt} and \symex ~\cite{rfcguided, symcert} had been shown as powerful tools for uncovering \textit{logical flaws} in the certificate validation code of many open-source TLS libraries. 

% % \fuzzing, in general, operates by mutating valid seed certificates to generate irregular inputs, which can reveal unexpected, potentially problematic behaviors in the implementation under scrutiny. \symex, on the other hand, systematically explores all possible paths a program could take during its execution, helping to reveal more deeply embedded logical bugs. 

% % While these techniques have successfully identified numerous noncompliance issues, they naturally bear the risk of false negatives-- some logical flaws remain undetected, especially when those are common across all tested libraries. To counter this challenge, the presence of a reference implementation that could serve as an oracle and provide a true standard, against which the test results can be verified, became crucial. Therefore, developing a formally-verified reference implementation is the primary goal of the work presented in this paper.

% \textbf{Developing High-assurance Implementations:} Several efforts have already been made to implement formally-verified cryptographic libraries~\cite{bond2017vale, protzenko2020evercrypt, zinzindohoue2017hacl}. However, creating a formally-verified implementation for \xfon CCVL is nontrivial due to the context-sensitivity of \der-encoded \xfon certificate grammar~\cite{debnath2021re}. Still, there are some re-engineering and formal verification efforts toward developing a high-assurance \xfon CCVL implementation. For example, several works developed a provably correct parser for \xfon certificates that can yield formally-verified code for certificate parsing~\cite{ramananandro2019everparse, ni2023asn1}. Barenghi \etal attempted to formulate \textit{context-free} specifications for \xfon~\cite{barenghi2018systematic}. Larisch \etal proposed to separate high-level certificate validation policies from low-level validation mechanisms~\cite{larisch2022hammurabi}. Tao \etal developed a memory-safe and formally correct encoder for \xfon certificates~\cite{tao2021dice}, while our work primarily targets certificate decoding. Despite advancements, all these attempts come with limitations, such as restricted crypto support, the simplification of \xfon grammar to avoid context-sensitivity or no comprehensive assurance for parsing and semantic requirements. Though the re-engineering effort of Debnath \etal showed a clear separation of the parsing and semantic requirements with individual formal representations for both sets of requirements~\cite{debnath2021re}, their implementation is not formally-verified, which is the research gap we address in this paper.

% \textbf{Measurement Studies on Insecure Deployment:} Some measurement studies have unveiled that the \xfon PKI is intentionally deployed to allow TLS interceptions by antivirus programs, parental control applications, middleboxes, and proxy servers~\cite{de2016killed, durumeric2017security, waked2018intercept, huang2014analyzing, debnath2020tls}. This intervention disrupts the end-to-end security guarantee that TLS is supposed to provide, posing potential security risks. Furthermore, several studies also underlined a key issue: \textit{user unawareness}. Many users lack a proper understanding of \xfon PKI and TLS, potentially overlooking their browser's certificate-related warnings and, in the worst case helping adversaries compromise their own trust anchors~\cite{sasse2015scaring, ukrop2019will, felt2014experimenting, akhawe2013alice, schechter2007emperor, sunshine2009crying}.

% \textbf{Enhancements and Alternatives to X.509 PKI:} One of the key research problems in the \xfon PKI is to find how to swiftly and effectively relay revocation information to users to minimize the window of vulnerability. This window occurs between the instance a certificate is revoked and when this information reaches the end-user, during which an attacker could potentially exploit the invalidated certificate. The traditional methods, such as Certificate Revocation List (\crl)~\cite{cooper2008internet} and the Online Certificate Status Protocol (\ocsp)~\cite{ocsp}, often suffer from latency issues and excessive network overhead, respectively. A range of innovative solutions have emerged to counter these limitations. For instance, \crlite optimizes the process by condensing all CRLs into a more manageable data structure, which significantly enhances the speed of revocation status queries~\cite{crlite}. \ocspstapling is another such improvement, where the server periodically obtains the \ocsp response and then delivers it to the client along with the certificate, reducing the need for individual \ocsp requests by clients~\cite{oscpstple}. More recent developments include browser-centric solutions such as \onecrl~\cite{onecrl} from Mozilla and \crlsets~\cite{crlset} from Google, which employ a rapidly updatable, centralized list of revoked certificates.

% Another research area aims to enhance the current trust model of \xfon PKI to improve its reliability and security. The \xfon PKI model operates under the substantial assumption that CAs are trustworthy entities that always diligently authenticate an identity before certificate issuance. Nevertheless, real-world security breaches have illustrated that CAs can be negligent or compromised, resulting in certificates issued to incorrect identities~\cite{di10, di12, di9, di8, di6, di11, amann2013no, di3, di1, di2, di4, di7, landscape, durumeric2013analysis, chung2016measuring, kumar2018tracking, ma2021s, levillain2012one, delignat2014web}. In response, researchers have proposed log-based solutions to document certificate issuance events on a central log-server, allowing any interested party to scrutinize CA actions~\cite{sk, ct1, cirt, policert, aki, arpki, dtki, matsumoto2020caps}. Although these log-based solutions decentralize the absolute trust placed in CAs, distributing trust among other entities within the PKI framework, these introduce additional trust in the logs. This trust distribution issue is recently addressed by incorporating \textit{blockchain} technology into log-server operations, effectively decentralizing trust~\cite{namecoin, certcoin, ikp, pbcert, certledger, bpki, al2017scpki, wan2018bki}. Despite the potential benefits of leveraging \textit{blockchain}, none of these have any real-world deployment yet.

% Alternative trust models to \xfon PKI also exist, such as \sdsi~\cite{spki, clarke2001certificate, rivest1996sdsi} and \pgp~\cite{pgp, callas2007rfc}. While these models offer innovative solutions, they are generally seen as less scalable for broad internet usage involving billions of users. For instance, the \sdsi model is predicated on using local names and localized trust, which may not scale well in a global context. Similarly, the \pgp web-of-trust model, while being very flexible, requires a significant amount of manual intervention, making it impractical for large-scale systems. Another alternative is the \dane protocol~\cite{hoffman2012dns}, which leverages the \dnssec~\cite{arends2005rfc} infrastructure to bind \xfon certificates to \dns names. This circumvents the need for CAs entirely by publishing \tlsa records in \dns that specify which certificates or CA should be trusted for a particular service. However, the \dane protocol has its own set of complexities and challenges, including the need for widespread \dnssec adoption, which has been slow due to various technical and operational challenges~\cite{dnssecdeploy}. While all these research efforts propose to significantly improving the \xfon PKI's trust model, clients still play a crucial role in validating certificates in most of these solutions. Thus, having a formally-verified reference implementation for \xfon CCVL still remains as essential.


% Efforts to create formally verified cryptographic libraries have been made in the recent past; however, developing a formally verified implementation for X.509 certificate chain validation is challenging, particularly due to the context-sensitive nature of DER-encoded X.509 certificate grammar. Some re-engineering and formal verification efforts have been directed towards developing high-assurance X.509 CCVL implementations. For instance, provably correct parsers for X.509 certificates have been developed to yield formally-verified code for certificate parsing [5, 6]. Barenghi et al. attempted to create context-free specifications for X.509 [7], while Larisch et al. proposed separating high-level certificate validation policies from low-level mechanisms [8]. Tao et al. focused on developing a memory-safe and formally correct encoder for X.509 certificates [9], in contrast to our work, which primarily targets certificate decoding.


% Despite these advancements, these efforts often face limitations like limited cryptographic support, simplification of X.509 grammar to address context-sensitivity, or lack comprehensive assurance for parsing and semantic requirements. The re-engineering work of Debnath et al. demonstrated a clear separation of parsing and semantic requirements with individual formal representations [10], but their implementation is not formally verified. Our paper addresses this research gap by presenting a formally-verified implementation of X.509 CCVL.




% X et al. provide a framework, Everparse, to automatically generate efficient zero-copy low-level parsers and serializers in C from declarative descriptions of tag-length-value (TLV) binary message formats. The generated parsers and serializers are formally verified in F* and guaranteed to be memory-safe, functionally correct, and non-malleable. Y et al. propose ASN1*, which extends Everparse with new parser combinators for ASN.1 DER specifications with non-malleability proofs, and the extracted parsers in OCaml are empirically evaluated against different X.509 certificates.